{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt-get install pkg-config\n",
    "# pkg-config --modversion opencv\n",
    "# sudo apt-get install build-essential cmake\n",
    "# sudo apt-get install freeglut3 freeglut3-dev\n",
    "# sudo apt-get install glew-utils glee-dev\n",
    "# sudo apt-get install libglew-dev\n",
    "# sudo apt-get install libjpeg-dev libtiff5-dev libpng-dev\n",
    "# sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libxvidcore-dev libx264-dev libxine2-dev\n",
    "# sudo apt-get install libv4l-dev v4l-utils\n",
    "# sudo apt-get install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev\n",
    "# sudo apt-get install libgtk2.0-dev\n",
    "# sudo apt-get install mesa-utils libgl1-mesa-dri libgtkgl2.0-dev libgtkglext1-dev\n",
    "# sudo apt-get install libatlas-base-dev gfortran libeigen3-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ~\n",
    "# cd sw/\n",
    "# mkdir opencv\n",
    "# cd opencv\n",
    "# wget -O opencv.zip https://github.com/opencv/opencv/archive/4.2.0.zip\n",
    "# unzip opencv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.2.0.zip\n",
    "# unzip opencv_contrib.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd opencv-4.2.0/\n",
    "# mkdir build\n",
    "# cd buil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 환경 설정 잠시 정지시킴\n",
    "# sudo apt-get install python2.7-dev python3-dev python-numpy python3-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# /home/bitai/anaconda3/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 경로를 잘 파악하고 있다면 문제 없음\n",
    "# cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=OFF -D WITH_IPP=OFF -D \n",
    "WITH_1394=OFF -D BUILD_WITH_DEBUG_INFO=OFF -D BUILD_DOCS=OFF -D INSTALL_C_EXAMPLES=ON -D \n",
    "INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF -D WITH_QT=OFF -D \n",
    "WITH_GTK=ON -D WITH_OPENGL=ON -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-4.2.0/modules -D WITH_V4L=ON -D\n",
    "WITH_FFMPEG=ON -D WITH_XINE=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D OPENCV_GENERATE_PKGCONFIG=ON ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다상의 파이썬 경로를 파악하지 못한다면 아래 방식으로\n",
    "# cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=OFF -D WITH_IPP=OFF -D \n",
    "WITH_1394=OFF -D BUILD_WITH_DEBUG_INFO=OFF -D BUILD_DOCS=OFF -D INSTALL_C_EXAMPLES=ON -D \n",
    "INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF -D WITH_QT=OFF -D \n",
    "WITH_GTK=ON -D WITH_OPENGL=ON -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-4.2.0/modules -D WITH_V4L=ON -D \n",
    "WITH_FFMPEG=ON -D WITH_XINE=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D OPENCV_GENERATE_PKGCONFIG=ON -D \n",
    "PYTHON3_INCLUDE_DIR=/home/bitai/anaconda3/include/python3.7m/ -D \n",
    "PYTHON3_NUMPY_INCLUDE_DIRS=/home/bitai/anaconda3/lib/python3.7/site-packages/numpy/core/include/ -D\n",
    "PYTHON3_PACKAGES_PATH=/home/bitai/anaconda3/lib/python3.7/site-packages -D PYTHON3_LIBRARY=/home/bitai/anaconda3/\n",
    "lib/libpython3.7m.so ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat /proc/cpuinfo | grep processor | wc -l\n",
    "# time make -j12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat /etc/ld.so.conf.d/*\n",
    "# sudo ldconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ~/proj/\n",
    "# mkdir test\n",
    "# cd test\n",
    "# g++ -o facedetect /usr/local/share/opencv4/samples/cpp/facedetect.cpp $(pkg-config opencv4 --libs --cflags)\n",
    "# ./facedetect --cascade=\"/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml\n",
    "\" --nested-cascade=\"/usr/local/share/opencv4/haarcascades/haarcascade_eye_tree_eyeglasses.xml\" --scale=1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 설정 다시 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래픽 카드는 이미지 처리 시 메모리 복사가 일어나는데 메모리는 3번째로 느리므로(레지스터>캐시메모리S>메모리D>I/O) 엄청 느려짐.\n",
    "\n",
    "\n",
    "# CNN 딥신경망 분류 중 하나. 주로 컴퓨터 비전(대상을 보고 인식)이나 이미지 처리 분야에서 사용. -인식, 분류, 식별\n",
    "# 이미지를 인식하고 각 이미지에 적합한 라벨을 붙이는 역할\n",
    "# 입력레이어, 결과레이어, 숨김레이어(완전연결레이어, 합성곱레이어, 활성화함수 역할의 단일RELU레이어, 정규화레이어, 풀링레이어)\n",
    "# CNN 아키텍처\n",
    "# 1. 입력 이미지\n",
    "# 2. 합성곱 레이어: 특성탐지기(행렬,패턴)을 사용해 특성맵(작은이미지)을 얻는다. conv2D\n",
    "# 3. 풀링 레이어: 중요한 특성은 남기고 중요하지 않은 정보는 무시해 더 작은 이미지를 얻는다.(최대풀링-최대값픽, 최소풀링, 평균풀링) Maxpool2D\n",
    "# 4. 플래트닝: 풀링된 특성맵(여러개)을 펴서 ANN 입력 형태인 하나의 열(행->열)로 만든다. Flatten()\n",
    "\n",
    "# CNN 레이어 추가 시 Conv2D(32, 3, 3: 크기가 3x3인 특성탐지기 32개. 처음에는 32로 시작 후에 필요에 때라 64나 128로 늘려간다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 5 4 4 3 1 2]\n",
      " [4 0 3 6 5 3 3]\n",
      " [3 7 3 9 4 9 9]\n",
      " [1 8 9 7 7 7 6]\n",
      " [5 2 3 0 9 0 1]\n",
      " [1 8 6 0 1 4 7]\n",
      " [7 3 6 9 6 3 5]]\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randint(0, 10, (7, 7))\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_np = np.ones([7, 7])\n",
    "\n",
    "print(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.array([-1, 0, 1])\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(kernel))\n",
    "print(type(img_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv = cv2.resize(img_np, (7,7))\n",
    "\n",
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [ 0]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "kernel = cv2.resize(kernel, (1, 3))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img_cv))\n",
    "print(type(kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv[0][0] = 0\n",
    "img_cv[3][3] = 2\n",
    "img_cv[6][6] = 3\n",
    "\n",
    "# filter2D: Convlution이 라플라스 변환과 푸리에 변환을 가짐\n",
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt-get install ctags cscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라플라스 변환 => 전달 함수를 얻기 위해 계산\n",
    "# 입력 대 출력비를 구하겠다.\n",
    "# 입력이 10, 출력이 7, 입출력비: 7/10\n",
    "# 입력이 y'' = y' +3y + 2\n",
    "# 출력이 y' = 3e^3x => y = e^3x\n",
    "# 라플라스 변환을 통해 상수로 만들 어 입출력비를 계산할 수 있게 된다.\n",
    "# integral 0 ~ inf f(t)=e^-st dt\n",
    "\n",
    "# 라플라스변환은 주어진 식을 간단한 식으로 변환한 뒤, 변형된 식을 풀고 그 해를 다시 원식으로 변환한다.\n",
    "# 선형 동역학계와 같은 미분 방정식을 풀 때 유용하게 사용된다. 피에르시몽 라플라스의 이름을 따 붙여졌다.\n",
    "# 라플라스 변환을 이용하면, 미분 방정식을 계수방정식으로 변환하여, 문제들을 쉽게 해결 할 수 있는 장점이 있다. \n",
    "# 초깃값 문제의 경우 일차적으로 일반해를 구하는 단계가 필요없게 되고, 비제차 미분방정식의 경우에는 대응하는 제차미분방정식을 먼저 풀 필요가 없다.\n",
    "\n",
    "# 푸리에변환은 시간에 대한 함수(혹은 신호)를 함수를 구성하고 있는 주파수 성분으로 분해하는 작업이다.\n",
    "# 시간의 영역에서의 미분연산은 주파수 영역에서 곱셈과 같아서, 미분방정식은 주파수 영역에서 더 쉽게 분석되기도 한다.\n",
    "# 또한, 시간 영역에서의 합성곱 (convolution)은 주파수 영역에서 평범한 곱셈과 같다.\n",
    "# 원하는 연산이 끝난 후에, 결과에 대한 변환으로 시간 영역으로의 돌아갈 수 있다. \n",
    "\n",
    "\n",
    "# Low Pass Filter(LPF 설계법) - ID Convolution\n",
    "# 전달함수 -> 실제값을 필터링하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(\n",
    "    Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30752)             0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(128, activation = 'relu'))\n",
    "classifier.add(Dense(128, activation = 'relu'))\n",
    "classifier.add(Dense(128, activation = 'relu'))\n",
    "classifier.add(Dense(128, activation = 'relu'))\n",
    "classifier.add(Dense(1, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity13.ipynb  Datasets\t    Exercise20.ipynb  Exercise22.ipynb\r\n",
      "Activity14.ipynb  Exercise19.ipynb  Exercise21.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset  'test images'\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set  training_set\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  dogs\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  dogs\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainSet = train_gen.flow_from_directory(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/training_set',\n",
    "    target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
    "testSet = test_gen.flow_from_directory('Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/test_set',\n",
    "    target_size = (64, 64), batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 43s 433ms/step - loss: 7.8057 - accuracy: 0.4881 - val_loss: 7.7009 - val_accuracy: 0.4950\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 38s 384ms/step - loss: 7.7914 - accuracy: 0.4891 - val_loss: 7.4912 - val_accuracy: 0.5088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b4812a0d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "classifier.fit_generator(trainSet, steps_per_epoch = int(10000/batch_size), epochs = 2, validation_data = testSet,\n",
    "    validation_steps = int(2500/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.load_img('test_image_2.jpg', target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "new_image = image.img_to_array(new_image)\n",
    "new_image = np.expand_dims(new_image, axis = 0)\n",
    "\n",
    "result = classifier.predict(new_image)\n",
    "#trainSet.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
